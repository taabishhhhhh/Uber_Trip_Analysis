{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a48e0d-eecc-47fd-a0c6-0ca4d408a676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 03 â€” Train/Test Split (Time-Series Aware)\\nThis notebook loads the engineered dataset, selects model features, and performs a **time-ordered train/test split** to prepare data for model building.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 03 â€” Train/Test Split (Time-Series Aware)\n",
    "This notebook loads the engineered dataset, selects model features, and performs a **time-ordered train/test split** to prepare data for model building.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3ffe11-f6a4-42f5-9838-57bac3df293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3393a3-2102-4564-a1f9-341fb258b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders for storing processed data & models\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"Data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66ee1ff-0f82-41f4-9fc9-f101a7738d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ðŸ“Œ Load Engineered Dataset  \\nIf processed features already exist â†’ load them.  \\nElse â†’ recompute them exactly like Feature Engineering file. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ðŸ“Œ Load Engineered Dataset  \n",
    "If processed features already exist â†’ load them.  \n",
    "Else â†’ recompute them exactly like Feature Engineering file. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba7d41f-f226-45ac-9af3-c98ad89b6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (348, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_number</th>\n",
       "      <th>date</th>\n",
       "      <th>active_vehicles</th>\n",
       "      <th>trips</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>trips_rolling_mean_3</th>\n",
       "      <th>trips_rolling_mean_7</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3147</td>\n",
       "      <td>19974</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12138.000000</td>\n",
       "      <td>10915.857143</td>\n",
       "      <td>6903.0</td>\n",
       "      <td>9537.0</td>\n",
       "      <td>7679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02765</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>196</td>\n",
       "      <td>1001</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9292.666667</td>\n",
       "      <td>10897.142857</td>\n",
       "      <td>19974.0</td>\n",
       "      <td>6903.0</td>\n",
       "      <td>9537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02682</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>890</td>\n",
       "      <td>5506</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8827.000000</td>\n",
       "      <td>11431.571429</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>19974.0</td>\n",
       "      <td>6903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02617</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>1137</td>\n",
       "      <td>7065</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4524.000000</td>\n",
       "      <td>8237.857143</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>19974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02598</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>785</td>\n",
       "      <td>4768</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5779.666667</td>\n",
       "      <td>7822.000000</td>\n",
       "      <td>7065.0</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_number       date  active_vehicles  trips day_of_week  \\\n",
       "0                  B02764 2015-01-02             3147  19974      Friday   \n",
       "1                  B02765 2015-01-02              196   1001      Friday   \n",
       "2                  B02682 2015-01-02              890   5506      Friday   \n",
       "3                  B02617 2015-01-02             1137   7065      Friday   \n",
       "4                  B02598 2015-01-02              785   4768      Friday   \n",
       "\n",
       "   is_weekend  month  day  trips_rolling_mean_3  trips_rolling_mean_7  \\\n",
       "0           0      1    2          12138.000000          10915.857143   \n",
       "1           0      1    2           9292.666667          10897.142857   \n",
       "2           0      1    2           8827.000000          11431.571429   \n",
       "3           0      1    2           4524.000000           8237.857143   \n",
       "4           0      1    2           5779.666667           7822.000000   \n",
       "\n",
       "     lag_1    lag_2    lag_3  \n",
       "0   6903.0   9537.0   7679.0  \n",
       "1  19974.0   6903.0   9537.0  \n",
       "2   1001.0  19974.0   6903.0  \n",
       "3   5506.0   1001.0  19974.0  \n",
       "4   7065.0   5506.0   1001.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option A: load existing engineered CSV\n",
    "engineered_path = \"Data/processed/engineered.csv\"\n",
    "\n",
    "if os.path.exists(engineered_path):\n",
    "    data = pd.read_csv(engineered_path, parse_dates=['date'])\n",
    "else:\n",
    "    # Option B: compute features inline (same logic as 02_feature_engineering)\n",
    "    data = pd.read_csv(\"Data/Uber-Jan-Feb-FOIL.csv\")\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values('date')\n",
    "\n",
    "    data['day_of_week'] = data['date'].dt.day_name()\n",
    "    data['is_weekend'] = data['day_of_week'].isin(['Saturday','Sunday']).astype(int)\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['day'] = data['date'].dt.day\n",
    "\n",
    "    data['trips_rolling_mean_3'] = data['trips'].rolling(window=3).mean()\n",
    "    data['trips_rolling_mean_7'] = data['trips'].rolling(window=7).mean()\n",
    "\n",
    "    data['lag_1'] = data['trips'].shift(1)\n",
    "    data['lag_2'] = data['trips'].shift(2)\n",
    "    data['lag_3'] = data['trips'].shift(3)\n",
    "\n",
    "    data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Save engineered version for future fast loading\n",
    "    data.to_csv(engineered_path, index=False)\n",
    "    print(\"Saved engineered features to:\", engineered_path)\n",
    "\n",
    "print(\"Loaded data shape:\", data.shape)\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae2b80e-9bfe-4f1a-9ae8-865906fc07af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ðŸ“Œ Select Features for Model Training  \\nThese features must match exactly with Feature Engineering output.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ðŸ“Œ Select Features for Model Training  \n",
    "These features must match exactly with Feature Engineering output.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4e3058-1ad6-4695-915d-69335987385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'active_vehicles', 'is_weekend', 'month', 'day',\n",
    "    'trips_rolling_mean_3', 'trips_rolling_mean_7',\n",
    "    'lag_1', 'lag_2', 'lag_3'\n",
    "]\n",
    "\n",
    "X = data[features].copy()\n",
    "y = data['trips'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa902cd-e4c2-4672-98ff-50d7779c5fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ðŸ“Œ Time-Series Train/Test Split  \\n- No shuffling (very important).  \\n- Last 20% of data = test set.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ðŸ“Œ Time-Series Train/Test Split  \n",
    "- No shuffling (very important).  \n",
    "- Last 20% of data = test set.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ffdcd4-f9c4-4570-bdb5-c6e9956eca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (278, 9) | X_test: (70, 9)\n",
      "y_train: (278,) | y_test: (70,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape, \"| y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b2a3b5-a5f5-4779-a2d0-3a2087359fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ“Œ Save Train/Test Data  \\nWe save both CSV (easy inspection) and Joblib (fast loading, used by Streamlit app).'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ðŸ“Œ Save Train/Test Data  \n",
    "We save both CSV (easy inspection) and Joblib (fast loading, used by Streamlit app).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42970057-42f7-43ef-8830-50e4768e2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed splits to Data/processed/ and models/\n"
     ]
    }
   ],
   "source": [
    "# Save as CSV\n",
    "X_train.to_csv(\"Data/processed/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"Data/processed/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"Data/processed/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"Data/processed/y_test.csv\", index=False)\n",
    "\n",
    "# Save as Joblib\n",
    "joblib.dump(X_train, \"models/X_train.joblib\")\n",
    "joblib.dump(X_test, \"models/X_test.joblib\")\n",
    "joblib.dump(y_train, \"models/y_train.joblib\")\n",
    "joblib.dump(y_test, \"models/y_test.joblib\")\n",
    "\n",
    "print(\"Saved processed splits to Data/processed/ and models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96d096c-7ab4-4382-a6e3-328d3d75b57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ðŸ“Œ Validate Time Ordering  \\nEnsure that:\\n- Last training date < First test date '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ðŸ“Œ Validate Time Ordering  \n",
    "Ensure that:\n",
    "- Last training date < First test date \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e844d17-3901-44e6-8fcd-8dd83b98ee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train last date: 2015-02-17 00:00:00\n",
      "Test first date: 2015-02-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_last_date = data.iloc[len(X_train)-1]['date']\n",
    "test_first_date = data.iloc[len(X_train)]['date']\n",
    "\n",
    "print(\"Train last date:\", train_last_date)\n",
    "print(\"Test first date:\", test_first_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "844d9776-bdd9-42dd-b2a5-04fe5b959ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' âœ… Train/Test Split Summary  \\n\\n- Loaded engineered dataset  \\n- Ensured deterministic features  \\n- Selected 9 final model features  \\n- Performed **time-aware** train/test split  \\n- Saved all processed files for:\\n  - Model Building notebook (Notebook 04)\\n  - Streamlit App deployment  \\n\\nThis prepares the dataset for building our machine learning models.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" âœ… Train/Test Split Summary  \n",
    "\n",
    "- Loaded engineered dataset  \n",
    "- Ensured deterministic features  \n",
    "- Selected 9 final model features  \n",
    "- Performed **time-aware** train/test split  \n",
    "- Saved all processed files for:\n",
    "  - Model Building notebook (Notebook 04)\n",
    "  - Streamlit App deployment  \n",
    "\n",
    "This prepares the dataset for building our machine learning models.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8711c-6e3e-4c17-b731-cb0dee1a3803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
